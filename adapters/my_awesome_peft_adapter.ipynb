{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PEFT stands for parameter-efficient fine-tuning. Like the adapters\n",
        "library, you can create PEFT adapters with minimal effort.\n",
        "\n",
        "Peft, like the adapters library, works with the transformers library.\n",
        "\n",
        "https://github.com/huggingface/peft\n",
        "\n",
        "Learn how to create your own PEFT adapters.\n",
        "\n",
        "In this notebook, you can play with an adapter I created and uploaded\n",
        "on Hugging Face:\n",
        "\n",
        "https://huggingface.co/solwol/roberta-sentiment-classifier-peft\n",
        "\n",
        "The `peft` and `adapters` libraries work in a very similar way. The Adapters library has more adapter configuration options.\n",
        "\n",
        "With PEFT, I used `LoRA` (low-rank adaptation) adapter configurations.\n",
        "\n",
        "When working with the adapters library, I used a configuration called the `seq_bn` (sequential bottle-neck) adapter.\n",
        "\n",
        "Adapters library also supports `LoRa`"
      ],
      "metadata": {
        "id": "qMneE97l37Px"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9X76yu0BDWJ"
      },
      "outputs": [],
      "source": [
        "!pip --q install transformers peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, RobertaConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "config = RobertaConfig.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    id2label={ 0: \"üëé\", 1: \"üëç\"}\n",
        ")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", config=config)\n",
        "model = PeftModel.from_pretrained(model, \"solwol/roberta-sentiment-classifier-peft\")"
      ],
      "metadata": {
        "id": "Gmt26qfOqdm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TextClassificationPipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "R7-Lcu8pTFgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\"PEFT is awesome!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH7dAQV00_GB",
        "outputId": "270e39dd-1e07-427d-a8b1-93d742f87c47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'üëç', 'score': 0.9878240823745728}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}